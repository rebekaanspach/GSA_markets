{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dddd1022",
   "metadata": {},
   "source": [
    "# Uncertainty on market shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8970c3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2, 6)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import brightway2 as bw\n",
    "import bw2calc as bc\n",
    "import bw2data as bd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import presamples as ps\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from functions import make_dirichlet_distribution, get_elec_input, create_presamples, query_for_activities\n",
    "ps.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5eaf8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.projects.set_current(\"UK-wood-clca\")\n",
    "cutoff391 = bw.Database('cutoff-3.9.1')\n",
    "\n",
    "test = bw.Database('mydb3')\n",
    "\n",
    "fu = test.get('0cf1f43a31e143b5bc5c06f8979f08b8')\n",
    "\n",
    "\n",
    "all_demands = [{fu: 1}]\n",
    "d_label = [\"fu\"]\n",
    "\n",
    "methods = [\n",
    "     ('ReCiPe 2016 v1.03, midpoint (H)', 'climate change', 'global warming potential (GWP1000)'), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "011ab5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'market 0' (unit, GLO, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae3cd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fu.get('classifications', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f58ac3",
   "metadata": {},
   "source": [
    "# Initialising monte calro lca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "886e9dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bw_helpers import sample_results, MyMonteCarloLCA, collect_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9350ac2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 312 ms\n",
      "Wall time: 321 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.999999905005097"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "all_demand_dict = all_demands[0].copy()\n",
    "for other_demand in all_demands[1:]:\n",
    "    all_demand_dict.update(other_demand)\n",
    "\n",
    "db = ['mydb']\n",
    "\n",
    "indices = [1,1]\n",
    "\n",
    "clca = MyMonteCarloLCA(all_demand_dict, \n",
    "                               method=methods[0], \n",
    "                               #presamples = presample,\n",
    "                               final_activities=[],\n",
    "                               database_name = db, \n",
    "                               tech_indices=None,\n",
    "                               bio_indices=None,\n",
    "                               include_only_specific_bio_uncertainty= True, \n",
    "                               include_only_specific_exc_uncertainty = True,\n",
    "                               seed =False)\n",
    "next(clca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9674c",
   "metadata": {},
   "source": [
    "# Load results of recursive calulcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "572eb5db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/.../GSA_markets\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m indices \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkets_to_screen/test_indices.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#categories = pd.read_csv(\"presamples/soybean_categories.csv\")\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "sys.path.append('/.../GSA_markets')\n",
    "indices = pd.read_csv(\"markets_to_screen/test_indices.csv\")\n",
    "#categories = pd.read_csv(\"presamples/soybean_categories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "8767a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_list = list(indices.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "180ae602",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_activities_removed = list(set(indices_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "4d41b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities =[]\n",
    "for i in range(len(duplicate_activities_removed)):\n",
    "    db = bw.Database(duplicate_activities_removed[i][0])\n",
    "    activity = db.get(duplicate_activities_removed[i][1])\n",
    "    activities.append(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "cb2bb1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "33fac8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['market 1' (unit, GLO, None), 'market 0' (unit, GLO, None)]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be677b20",
   "metadata": {},
   "source": [
    "# Query exchanges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f101d139",
   "metadata": {},
   "source": [
    "Find all the exchanges of the selected activities. Filter and exclude any exchange that should not be sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "e0fcf08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchanges= MyMonteCarloLCA.get_exchanges_of_activity_wo_category(clca, activities)\n",
    "len(exchanges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "b70613bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchanges_units_sorted = [exc for exc in exchanges if exc['exchange']['unit'] == exc['activity']['unit']]\n",
    "len(exchanges_units_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "5a39f220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchanges = [exc for exc in exchanges_units_sorted if exc['tech_indices'][0] != exc['tech_indices'][1] ]\n",
    "len(exchanges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "2c5db7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exchanges = []\n",
    "#second_indices = [exc[\"tech_indices\"][1] for exc in exchanges_sorted]\n",
    "\n",
    "#for exc in exchanges_sorted:\n",
    "#    if second_indices.count(exc[\"tech_indices\"][1]) != 1:\n",
    "#        exchanges.append(exc)\n",
    "#len(exchanges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "78fe0c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities =[]\n",
    "for exc in exchanges:\n",
    "    activities.append(exc[\"activity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "177c51a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#activities = [activities[0],activities[1]]\n",
    "#activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "1536b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exchanges = [exchanges[0],exchanges[1]]\n",
    "#exchanges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b892a39b",
   "metadata": {},
   "source": [
    "## Morris sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "047a55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_to_group = {}\n",
    "group_counter = 1\n",
    "\n",
    "for entry in exchanges:\n",
    "    activity = entry['activity']\n",
    "    if activity not in activity_to_group:\n",
    "        activity_to_group[activity] = group_counter\n",
    "        group_counter += 1\n",
    "    # Add the group field to the entry\n",
    "    entry['group'] = activity_to_group[activity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "400914e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_problem(input_data):\n",
    "    # Initialize the output structure\n",
    "    result = {\n",
    " #      'groups': [],\n",
    "        'names': [],\n",
    "        'num_vars': 0,\n",
    "        'bounds': [],\n",
    "        'sample_scaled': True\n",
    "    }\n",
    "    print(input_data)\n",
    "\n",
    "    # Iterate over the input data\n",
    "    for item in input_data:\n",
    "        # Generate the 'name' as a string combining 'exchange' and 'activity'\n",
    "        name = f\"{item['exchange']}  to {item['activity']}\"\n",
    "        result['groups']= ( 'M1 mix', 'M1 mix',   'M0 mix',\n",
    "                           'M0 mix', )\n",
    "        result['names'].append(name)\n",
    "        result['num_vars'] = len(input_data)\n",
    "        if item['value']== 0.5:\n",
    "            bounds = [item['value']-0.5, item['value']+0.5]\n",
    "        else:\n",
    "            bounds = [item['value']-item['value']*1, item['value']+item['value']*1]\n",
    "        result['bounds'].append(bounds)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8178ce8",
   "metadata": {},
   "source": [
    "### Define problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "f5fdac79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tech_indices': [5, 3], 'activity': 'market 1' (unit, GLO, None), 'exchange': 'process 3' (unit, GLO, None), 'database': 'mydb3', 'value': 0.5, 'category': [], 'group': 1}, {'tech_indices': [6, 3], 'activity': 'market 1' (unit, GLO, None), 'exchange': 'process 2' (unit, GLO, None), 'database': 'mydb3', 'value': 0.5, 'category': [], 'group': 1}, {'tech_indices': [4, 1], 'activity': 'market 0' (unit, GLO, None), 'exchange': 'process 4' (unit, GLO, None), 'database': 'mydb3', 'value': 0.5, 'category': [], 'group': 2}, {'tech_indices': [8, 1], 'activity': 'market 0' (unit, GLO, None), 'exchange': 'process 1' (unit, GLO, None), 'database': 'mydb3', 'value': 0.5, 'category': [], 'group': 2}]\n"
     ]
    }
   ],
   "source": [
    "problem = define_problem(exchanges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "7693ec66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': [\"'process 3' (unit, GLO, None)  to 'market 1' (unit, GLO, None)\",\n",
       "  \"'process 2' (unit, GLO, None)  to 'market 1' (unit, GLO, None)\",\n",
       "  \"'process 4' (unit, GLO, None)  to 'market 0' (unit, GLO, None)\",\n",
       "  \"'process 1' (unit, GLO, None)  to 'market 0' (unit, GLO, None)\"],\n",
       " 'num_vars': 4,\n",
       " 'bounds': [[0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0]],\n",
       " 'sample_scaled': True,\n",
       " 'groups': ('M1 mix', 'M1 mix', 'M0 mix', 'M0 mix')}"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "a7325d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem ={'names': [\"'process 3' (unit, GLO, None)  to 'market 1' (unit, GLO, None)\",\n",
    "#  \"'process 2' (unit, GLO, None)  to 'market 1' (unit, GLO, None)\",\n",
    "#  \"'process 4' (unit, GLO, None)  to 'market 0' (unit, GLO, None)\",\n",
    "#  \"'process 1' (unit, GLO, None)  to 'market 0' (unit, GLO, None)\"],\n",
    "# 'num_vars': 4,\n",
    "# 'bounds': [[0.0, 1.0], [0.0, 1.0], [0.555, 0.5555], [0.555, 0.5555]],\n",
    "# 'sample_scaled': True,\n",
    "# 'groups': ('M1 mix', 'M1 mix', 'M0 mix', 'M0 mix')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f0d9e",
   "metadata": {},
   "source": [
    "### Sample X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "209bcfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_group(x):\n",
    "    total_sum = x.sum()\n",
    "    if len(x)>1:\n",
    "        if total_sum == 0:\n",
    "            return pd.Series(1 / len(x), index=x.index)  # Assign equal contribution\n",
    "        else:\n",
    "            return x / total_sum\n",
    "    else: \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "9f4f2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = [500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "7df4d866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from SALib.sample.morris import sample\n",
    "\n",
    "X = {} \n",
    "samples_dict = {}\n",
    "samples_without_norm = {}\n",
    "#range(10, 100, 10)\n",
    "\n",
    "for trajectory in trajectories:\n",
    "    x = sample(problem, N=trajectory, num_levels =4)#calc_second_order=False)\n",
    "\n",
    "    samples = pd.DataFrame(x).T\n",
    "    samples_without_norm[trajectory] =samples.copy()\n",
    "    samples['groups'] = pd.Series(problem['names']).str.split(\" to \").str[-1]#assign market to be used during normalisation\n",
    "    \n",
    "    \n",
    "    value_columns = samples.columns.difference(['groups'])\n",
    "    \n",
    "    samples[value_columns] = samples.groupby('groups')[value_columns].transform(normalize_group)\n",
    "    samples= samples.drop(columns=['groups'])\n",
    "    samples = np.array(samples)\n",
    "\n",
    "    samples_normalized_with_zeros = np.insert(samples, 0, 0, axis=1)#initialisation problem\n",
    "    samples_normalized_with_zeros = np.insert(samples_normalized_with_zeros, 0, 0, axis=1)\n",
    "\n",
    "    X[trajectory] = samples_normalized_with_zeros\n",
    "    samples_dict[trajectory] =samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "054956eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#results_normalized =[]\n",
    "#for trajectory, samples in X.items():\n",
    "#    print(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a509e1",
   "metadata": {},
   "source": [
    "# update value with dirichlet distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6658908b",
   "metadata": {},
   "source": [
    "For each activity, the quantity (value) of exchanges is updated in `exc_ dict` so that they sum to 1. \n",
    "\n",
    "`ext_dict` is a dictionnary that stores exchange names, their indices, their quantity (value) and their source activity.\n",
    "\n",
    "The values summing to one are sampled using dirichlet distribution (N= mc) with different `concentration values`.\n",
    "For each `concentration value` a new `exc_dict` is stored.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "da4b0a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_normalized ={}\n",
    "for trajectory, samples in X.items():\n",
    "    new_samples_normalized = [\n",
    "        {\n",
    "            'trajectory': trajectory,\n",
    "            'runs': len(X[trajectory][j]),\n",
    "            'indices': exc['tech_indices'],\n",
    "            'activity': exc['activity'],\n",
    "            'exchange': exc['exchange'],\n",
    "            'exc_database': exc['database'],\n",
    "            'act_database': exc['activity'][0],\n",
    "            'sample': X[trajectory][j],\n",
    "            'old_value': exc['value'],\n",
    "            #'index': i\n",
    "        }\n",
    "        for j, exc in enumerate(exchanges)\n",
    "]\n",
    "    results_normalized[trajectory] = new_samples_normalized\n",
    "\n",
    "\n",
    "#results_normalized.extend(new_samples_normalized)\n",
    "#all_results = pd.DataFrame(new_samples_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105cc2b",
   "metadata": {},
   "source": [
    "# create presamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb54c25",
   "metadata": {},
   "source": [
    "A presample is created for each `exc_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "69b84fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 5.06 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "presamples_data_normalized = {}\n",
    "presamples_indices_normalized = {}  \n",
    "\n",
    "for trajectory, samples in results_normalized.items():  # Assuming results_normalized is a dictionary\n",
    "    presamples_data_normalized[trajectory] = []  # Initialize empty list for this trajectory\n",
    "    presamples_indices_normalized[trajectory] = []  # Initialize empty list for this trajectory\n",
    "    \n",
    "    for exc in samples:\n",
    "        process = bw.Database(exc['exc_database']).get(exc['exchange'][1])\n",
    "        activity = bw.Database(exc['act_database']).get(exc['activity'][1])\n",
    "        value = exc['sample']\n",
    "\n",
    "        data, indices = create_presamples(\n",
    "            activity=activity,\n",
    "            process=process,\n",
    "            exchanges={\n",
    "                \"new_exchange\": process,\n",
    "                \"new_value\": lambda process: value\n",
    "            }\n",
    "        )\n",
    "\n",
    "        presamples_data_normalized[trajectory].append(data)\n",
    "        presamples_indices_normalized[trajectory].append(indices)\n",
    "\n",
    "    presamples_data_normalized[trajectory] = np.vstack(presamples_data_normalized[trajectory])\n",
    "    #presamples_data_dict_normalized[trajectory] = presamples_data_normalized[trajectory]\n",
    "    #presamples_indices_dict_normalized[trajectory] = presamples_indices_normalized[trajectory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "7f6e41c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_matrix_data = {}\n",
    "for trajectory, samples in results_normalized.items():\n",
    "    index_matrix_data_normalized = [\n",
    "        (globals()[f'presamples_data_normalized'][trajectory], \n",
    "         globals()[f'presamples_indices_normalized'][trajectory], 'technosphere')\n",
    "    ]\n",
    "    \n",
    "    index_id_normalized, index_path_normalized = ps.create_presamples_package(\n",
    "        matrix_data=index_matrix_data_normalized,\n",
    "    )\n",
    "    \n",
    "    index_matrix_data[trajectory] = {\n",
    "        'data': index_matrix_data_normalized,\n",
    "        'index_id': index_id_normalized,\n",
    "        'index_path': index_path_normalized\n",
    "    }\n",
    "    \n",
    "    globals()[f'index_id_normalized_{trajectory}'] = index_id_normalized\n",
    "    globals()[f'index_path_normalized_{trajectory}'] = index_path_normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341f2e6",
   "metadata": {},
   "source": [
    "# LCA calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "58c9eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "presamples = [{\"name\": size, \"runs\": len(X[size][0]), \"path\": [globals()[f'index_path_normalized_{size}']], \"number\": \"all\"} for size in trajectories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "199c44eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "for size in trajectories:\n",
    "    print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "98a8a215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.73 s\n",
      "Wall time: 2.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "indices = []\n",
    "results = []\n",
    "final_activities = []\n",
    "component_order = []\n",
    "\n",
    "results_by_name = {}\n",
    "\n",
    "for presample in presamples:\n",
    "    start_time = time.time()\n",
    "\n",
    "    clca = MyMonteCarloLCA(\n",
    "        all_demand_dict,\n",
    "        method=methods[0],\n",
    "        presamples=presample[\"path\"],\n",
    "        final_activities=final_activities,\n",
    "        database_name=db,\n",
    "        bio_indices=None,\n",
    "        tech_indices=None,\n",
    "        include_only_specific_bio_uncertainty=True,\n",
    "        include_only_specific_exc_uncertainty=True,\n",
    "    )\n",
    "\n",
    "    next(clca)\n",
    "\n",
    "    temp_results = collect_results(\n",
    "        clca,\n",
    "        all_demands,\n",
    "        final_activities,\n",
    "        len(samples_dict[presample[\"name\"]][0]),\n",
    "        methods[0],\n",
    "        d_label,\n",
    "        component_order,\n",
    "        database_name=db,\n",
    "        bio_indices=None,\n",
    "        tech_indices=None,\n",
    "        include_only_specific_bio_uncertainty=True,\n",
    "        include_only_specific_exc_uncertainty=True,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "\n",
    "    temp_results[\"category\"] = presample[\"name\"]\n",
    "    temp_results[\"runtime\"] = runtime \n",
    "    temp_results[\"runs\"] = presample[\"runs\"]\n",
    "\n",
    "    results_by_name[presample[\"name\"]] = temp_results\n",
    "\n",
    "\n",
    "morris_results = pd.concat(results_by_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "e830482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "morris_results.to_csv(r\"results/Simple_std_scores_sobol.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "1573ce1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>method</th>\n",
       "      <th>iteration</th>\n",
       "      <th>score</th>\n",
       "      <th>category</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">500</th>\n",
       "      <th>0</th>\n",
       "      <td>fu</td>\n",
       "      <td>climate change</td>\n",
       "      <td>0</td>\n",
       "      <td>9.030000</td>\n",
       "      <td>500</td>\n",
       "      <td>2.649468</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fu</td>\n",
       "      <td>climate change</td>\n",
       "      <td>1</td>\n",
       "      <td>5.050000</td>\n",
       "      <td>500</td>\n",
       "      <td>2.649468</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fu</td>\n",
       "      <td>climate change</td>\n",
       "      <td>2</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>500</td>\n",
       "      <td>2.649468</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fu</td>\n",
       "      <td>climate change</td>\n",
       "      <td>3</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>500</td>\n",
       "      <td>2.649468</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fu</td>\n",
       "      <td>climate change</td>\n",
       "      <td>4</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>500</td>\n",
       "      <td>2.649468</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>fu</td>\n",
       "      <td>climate change</td>\n",
       "      <td>1495</td>\n",
       "      <td>7.537500</td>\n",
       "      <td>500</td>\n",
       "      <td>2.649468</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>fu</td>\n",
       "      <td>climate change</td>\n",
       "      <td>1496</td>\n",
       "      <td>12.040000</td>\n",
       "      <td>500</td>\n",
       "      <td>2.649468</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>fu</td>\n",
       "      <td>climate change</td>\n",
       "      <td>1497</td>\n",
       "      <td>11.224000</td>\n",
       "      <td>500</td>\n",
       "      <td>2.649468</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>fu</td>\n",
       "      <td>climate change</td>\n",
       "      <td>1498</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>500</td>\n",
       "      <td>2.649468</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>fu</td>\n",
       "      <td>climate change</td>\n",
       "      <td>1499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500</td>\n",
       "      <td>2.649468</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario          method  iteration      score  category   runtime  \\\n",
       "500 0          fu  climate change          0   9.030000       500  2.649468   \n",
       "    1          fu  climate change          1   5.050000       500  2.649468   \n",
       "    2          fu  climate change          2  16.666667       500  2.649468   \n",
       "    3          fu  climate change          3  10.000000       500  2.649468   \n",
       "    4          fu  climate change          4  10.000000       500  2.649468   \n",
       "...           ...             ...        ...        ...       ...       ...   \n",
       "    1495       fu  climate change       1495   7.537500       500  2.649468   \n",
       "    1496       fu  climate change       1496  12.040000       500  2.649468   \n",
       "    1497       fu  climate change       1497  11.224000       500  2.649468   \n",
       "    1498       fu  climate change       1498  16.000000       500  2.649468   \n",
       "    1499       fu  climate change       1499   0.000000       500  2.649468   \n",
       "\n",
       "          runs  \n",
       "500 0     1502  \n",
       "    1     1502  \n",
       "    2     1502  \n",
       "    3     1502  \n",
       "    4     1502  \n",
       "...        ...  \n",
       "    1495  1502  \n",
       "    1496  1502  \n",
       "    1497  1502  \n",
       "    1498  1502  \n",
       "    1499  1502  \n",
       "\n",
       "[1500 rows x 7 columns]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morris_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3684de",
   "metadata": {},
   "source": [
    "# Sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "e8060678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tech_indices': [5, 3], 'activity': 'market 1' (unit, GLO, None), 'exchange': 'process 3' (unit, GLO, None), 'database': 'mydb3', 'value': 0.5, 'category': [], 'group': 1}, {'tech_indices': [6, 3], 'activity': 'market 1' (unit, GLO, None), 'exchange': 'process 2' (unit, GLO, None), 'database': 'mydb3', 'value': 0.5, 'category': [], 'group': 1}, {'tech_indices': [4, 1], 'activity': 'market 0' (unit, GLO, None), 'exchange': 'process 4' (unit, GLO, None), 'database': 'mydb3', 'value': 0.5, 'category': [], 'group': 2}, {'tech_indices': [8, 1], 'activity': 'market 0' (unit, GLO, None), 'exchange': 'process 1' (unit, GLO, None), 'database': 'mydb3', 'value': 0.5, 'category': [], 'group': 2}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'names': [\"'process 3' (unit, GLO, None)  to 'market 1' (unit, GLO, None)\",\n",
       "  \"'process 2' (unit, GLO, None)  to 'market 1' (unit, GLO, None)\",\n",
       "  \"'process 4' (unit, GLO, None)  to 'market 0' (unit, GLO, None)\",\n",
       "  \"'process 1' (unit, GLO, None)  to 'market 0' (unit, GLO, None)\"],\n",
       " 'num_vars': 4,\n",
       " 'bounds': [[0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0]],\n",
       " 'sample_scaled': True,\n",
       " 'groups': ('M1 mix', 'M1 mix', 'M0 mix', 'M0 mix')}"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = define_problem(exchanges)\n",
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "190c62e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SALib.analyze.morris import analyze\n",
    "SA_results={}\n",
    "for trajectory in trajectories:\n",
    "    samples_copy = np.array(samples_without_norm[trajectory].transpose(), dtype=np.float64)\n",
    "    results_SA_normalized = morris_results[morris_results['category']== trajectory]\n",
    "    \n",
    "    SA_normalized = analyze(problem, samples_copy, np.array(results_SA_normalized['score']), \n",
    "                            conf_level=0.95,  \n",
    "                            print_to_console=False, \n",
    "                       #     calc_second_order=False,\n",
    "                           \n",
    "          )\n",
    "\n",
    "    SA_results[trajectory] = pd.DataFrame(SA_normalized)\n",
    "len(samples_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "fd4548cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key in SA_results:\n",
    "#    SA_results[key]['names'] = ['M1', 'M0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "90c19bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_results_df = pd.concat([df.assign(index=k) for k, df in SA_results.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "3543a8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>mu</th>\n",
       "      <th>mu_star</th>\n",
       "      <th>sigma</th>\n",
       "      <th>mu_star_conf</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1 mix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.753038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.438400</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M0 mix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.813258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568146</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    names  mu   mu_star  sigma  mu_star_conf  index\n",
       "0  M1 mix NaN  4.753038    NaN      0.438400    500\n",
       "1  M0 mix NaN  6.813258    NaN      0.568146    500"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_results_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfd361d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "fdc5412c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ST_conf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ab\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ST_conf'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[432], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m SA_conf \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trajectory \u001b[38;5;129;01min\u001b[39;00m trajectories:\n\u001b[0;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber of trajectory\u001b[39m\u001b[38;5;124m'\u001b[39m: trajectory,\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m'\u001b[39m: SA_results[trajectory]\u001b[38;5;241m.\u001b[39mindex,\n\u001b[1;32m----> 6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mST_conf\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mSA_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mST_conf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      7\u001b[0m     })\n\u001b[0;32m      8\u001b[0m     SA_conf\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     10\u001b[0m SA_conf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(SA_conf, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ab\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ab\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ST_conf'"
     ]
    }
   ],
   "source": [
    "SA_conf = []\n",
    "for trajectory in trajectories:\n",
    "    df = pd.DataFrame({\n",
    "        'number of trajectory': trajectory,\n",
    "        'names': SA_results[trajectory].index,\n",
    "        'ST_conf': SA_results[trajectory]['ST_conf']\n",
    "    })\n",
    "    SA_conf.append(df)\n",
    "\n",
    "SA_conf = pd.concat(SA_conf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f7180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2948834",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime= pd.DataFrame({\n",
    "    'runtime in seconds':morris_results[\"runtime\"].unique(),\n",
    "    'number of trajectory':morris_results[\"category\"].unique(),\n",
    "    'number of runs':morris_results[\"runs\"].unique(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ef213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = mpl.figure.Figure(figsize=(10, 3), dpi=100)\n",
    "subfigures = f.subfigures(1, 3)\n",
    "\n",
    "sf1, sf2, sf3 = subfigures\n",
    "\n",
    "\n",
    "p1 = (\n",
    "    so.Plot(runtime, x=\"number of trajectory\", y=\"runtime in seconds\")\n",
    "    .add(so.Line())\n",
    " #   .layout(size=(3, 2))\n",
    "    .label(x=\"Number of N\", y=\"Runtime in seconds\",\n",
    "        title=\"Runtime per number of trajectories\", color=\"\")\n",
    "\n",
    ")\n",
    "p1.on(sf1).plot()\n",
    "\n",
    "p2 = (\n",
    "    so.Plot(SA_conf, x=\"number of trajectory\", y=\"ST_conf\", color= SA_results_df.index)\n",
    "    .add(so.Line())\n",
    "    .limit(x=(0, 4000),y=(0, 0.5))\n",
    "    .label(x=\"Number of N\", y=\"ST conf\",\n",
    "        title=\"ST confidence per number of trajectories\", color=\"\")\n",
    " #   .layout(size=(3, 2))\n",
    ")\n",
    "p2.on(sf2).plot()\n",
    "\n",
    "p3 = (\n",
    "    so.Plot(runtime, x=\"number of trajectory\", y=\"number of runs\")\n",
    "    .add(so.Line())\n",
    "  #  .limit(x=(0, 900),y=(0, 3000))\n",
    "    .label(x=\"number of N\", y=\"number of runs\",\n",
    "        title=\"ST confidence per number of trajectories\", color=\"\")\n",
    " #   .layout(size=(3, 2))\n",
    ")\n",
    "p3.on(sf3).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c996a1",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c4ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc868664",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    so.Plot(morris_results, x=\"score\")\n",
    "    .add(so.Bars(), so.Hist())\n",
    " #   .layout(size=(3, 2))\n",
    ")\n",
    "p.label(x=\"Climate change impact (GWP / kg CO$_{2e}$)\", y=\"Climate change impact (GWP / kg CO$_{2e}$)\", color=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca13adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(runtime, x=\"number of trajectory\", y=\"runtime in seconds\")\n",
    "    .add(so.Line())\n",
    " #   .layout(size=(3, 2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SA_test['activity'] = list(set(activities))\n",
    "#SA_test['category'] = categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a905a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SA_test.to_csv(\"results/SA_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab59d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ab",
   "language": "python",
   "name": "ab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
